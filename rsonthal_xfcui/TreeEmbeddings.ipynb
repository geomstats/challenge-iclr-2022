{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9URP693vfFs"
   },
   "source": [
    "# Challenge: Hyperbolic Embedding via Graph Learning\n",
    "Authors: Rishi Sonthalia and Xinyue Cui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb-QIJdjvrjH"
   },
   "source": [
    "## 1 Introduction\n",
    "\n",
    "Many different types of datasets are better represented in hyperbolic space as compared to Euclidean space. These are normally datasets that have semantically rich hierarchies such as text [35], social and other forms of networks [7,9,25,26], and cell development trees [16]. Other applications of hyperbolic representations have also been seen to be useful for computer vision and for other tasks [32,33,34]. Based off of the success of these applications, recently there has been great effort in developing hyperbolic versions of different neural networks - hyperbolic deep neural networks [4,39,46,47], hyperbolic convolutional neural networks [47,48], hyperbolic recurrent neural networks [39], hyperbolic transformers [40,47], and hyperbolic graph neural networks [42,43,45]. See survey [49] for many for example applications.  \n",
    "\n",
    "Additionally, people have looked at extending hyperbolic embeddings beyong hyperbolic manifolds to other hyperbolic structures such as Hierarchical Hyperbolic Spaces [38]. Work such as [36,37] have proven that phylogentic data live in these Hierarchical Hyperbolic Spaces.\n",
    "\n",
    "\n",
    "To take advantage of hyperbolic representations we need techniques that learn embed data into hyperbolic manifolds. Historiocally two different approaches have been taken to learning these embeddings. First, we learn these embeddings by solving an optimization problem. This could be done in a supervised on an unsupervised manner. Second, we learn combinatorial structures that are then combinatorially embedded into the hyperbolic manifold.\n",
    "\n",
    "### 1.1 Optimiation Based Methods. \n",
    "\n",
    "For unsupervised method, we are given a distance matrix or a distance matrix is extracted from the given data and then we set up an optimization problem that learns the embedding into the hyperbolic manifold. Concretely, let $D \\in \\mathbb{R}^{n \\times n}$ be the distance matrix, let $y_i$ for $i = 1, \\ldots, n$ be the vectors in the hyperbolic manifold $\\mathbb{H}^d$. Then we have a loss function $L := L(D, y_1, \\ldots, y_n)$ that we want to minimize. Examples of such methods include [2,4,17,18,41]. \n",
    "\n",
    "Supervised methods are methods that learn embeddings using neural networks. One common example is to learn work embeddings, works such as [50,51] present hyperbolic versions of standard word embedding techniques such as Word2Vec and GLoVe. Another approach to pick a random vector in $\\mathbb{H}^d$ as the initial embedding and this embedding is optimized during the training of the neural network. \n",
    "\n",
    "However, such approaches tend to have a few common issues. \n",
    "\n",
    "    1) The optimization problem is non convex and is very difficult to solve;\n",
    "    2) the otpimiation procedure is unstable and require large number of bits to accruately represent; or\n",
    "    3) the methods ignore the geometry of the input data;\n",
    "    4) the methods do not have any theoretical gaurantees. \n",
    "    \n",
    "### 1.2 Combinatorial Techniques. \n",
    "\n",
    "There also many combinatorial methods. These certain around two different technqiues. The first is to directly embed a given graph into a hyperbolic manifold []. Other methods exploit the tree like structure [] of hyperbolic space. For these methods, given a metric, we first learn a tree that approximates the given metric []. Then given this tree we either treat the tree as the hyperbolic representation or embed the tree in a hyperbolic manifold using Sarkars algorithms and its extensions []. \n",
    "\n",
    "### 1.3 This Notebook\n",
    "\n",
    "In this notebook, we would like to implement one such combinatorial method. Specifically, we present the latest tree learning method [] as well as Sarkars algorithm []. The structure of the notebook will be as follows\n",
    "\n",
    "     1) First we present some background on hyperbolic geometry from both the differential and algebraic view point\n",
    "     2) We present TreeRep and demonstrate how it can be used to construct trees from metrics\n",
    "     3) We present Sarkars algorithm and demonstrate how it can be used to embed data into hyperbolic disk. \n",
    "     4) We test the complete pipeline on real world and synthetic datasets to demonstrate that we get embeddings with low distortion. \n",
    " \n",
    "Other implementations of the above algorithms exist. TreeRep has two prior implementations. The first is in Julia and can be found at [] and the second in C++ and can be found at []. There are two prior implementations of Sarkars algorithm as well. Again there are in Julia [] and in C++ []. Both implementations for both algorithms have python wrappers. But to the best of our knowledge there does not exist a python version of the two algorithms. \n",
    "\n",
    "\n",
    "### 1.4 Related work\n",
    "\n",
    "There is another family of work related to these methods. That is idea of approximating general metrics by trees. Note here we do not have hyperbolic view of these metrics or of the trees just that trees are simple graphical structures. Such work includes []\n",
    "\n",
    "The final area of related work, is this the notion of metric embeddings and includes work such as []. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJxl-JMnhB-x"
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import networkx as nx\n",
    "import geomstats.backend as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "249LAcQIhJLl",
    "outputId": "d1e07c7f-5436-40bb-ceb8-faaf5be706d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import TreeRep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TreeRep - Reconstructing Trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb4FHT_0zFv6"
   },
   "source": [
    "## Synthetic Tests\n",
    "\n",
    "1) Recovering Known Trees\n",
    "2) Learing trees of random graphs\n",
    "3) Learing trees for Random points in hyperbolic space\n",
    "\n",
    "Embedding trees\n",
    "\n",
    "1) Show scaling effect of embedding\n",
    "2) Take random points in hyperbolic space learn tree and embed and then compare the points\n",
    "\n",
    "## Applications \n",
    "\n",
    "1) Pure embeddings, do the karate club graph\n",
    "2) Dimensionality reduction - take high dimensional data, learn tree, and then embed into two dimensional space\n",
    "3) Learn Tree structure, such as a phylogentic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "q7DkIMMkjqSn",
    "outputId": "2cc92c9f-4658-486c-bd24-e00f8c63cb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 13870\n",
      "289 288\n",
      "True False\n",
      "\n",
      "200 13941\n",
      "271 270\n",
      "True False\n",
      "\n",
      "200 13917\n",
      "273 272\n",
      "True False\n",
      "\n",
      "200 13873\n",
      "297 296\n",
      "True False\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-92aabcb869cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortest_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloyd_warshall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/algorithms/shortest_paths/dense.py\u001b[0m in \u001b[0;36mfloyd_warshall\u001b[0;34m(G, weight)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# could make this its own function to reduce memory costs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloyd_warshall_predecessor_and_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/algorithms/shortest_paths/dense.py\u001b[0m in \u001b[0;36mfloyd_warshall_predecessor_and_distance\u001b[0;34m(G, weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mdist_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                     \u001b[0mdist_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload \n",
    "reload(TreeRep)\n",
    "\n",
    "for trial in range(100,5000,100):\n",
    "  n = 200\n",
    "  G = nx.gnp_random_graph(200, 0.7)\n",
    "  for e in G.edges():\n",
    "      G[e[0]][e[1]]['weight'] = gs.random.rand()*10\n",
    "  d = nx.algorithms.shortest_paths.dense.floyd_warshall(G)\n",
    "  D = gs.zeros((n,n))\n",
    "  for i in range(n):\n",
    "    for j in range(n):\n",
    "      D[i,j] = d[i][j]\n",
    "\n",
    "  T = TreeRep.TreeRep(D)\n",
    "  T.learn_tree()\n",
    "  print(G.number_of_nodes(), G.number_of_edges())\n",
    "  print(T.G.number_of_nodes(),T.G.number_of_edges())\n",
    "  print(nx.is_k_edge_connected(T.G,1), nx.is_k_edge_connected(T.G,2))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jcEz9KurLb5"
   },
   "source": [
    "## 3.2 Sarkars Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Testing on Synthetic test\n",
    "\n",
    "### 3.3.1 Random Points on the hyperbolic manifold\n",
    "\n",
    "### 3.3.2 Random Sparse Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Testing it on real world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Bibliography\n",
    "\n",
    "[1] Thomas Blasius, Tobias Friedrich, Anton Krohmer, Soren Laue, Anton Krohmer, Soren Laue, Tobias Friedrich, and Thomas Blasius. 2018. Efficient Embedding of Scale-Free Graphs in the Hyperbolic Plane. IEEE/ACM Trans. Netw. 26, 2 (April 2018), 920–933. DOI:https://doi.org/10.1109/TNET.2018.2810186 \n",
    " \n",
    " [2] Cvetkovski, Andrej and Crovella, Mark (2016) \"Multidimensional Scaling in the Poincaré disk,\" Applied Mathematics & Information Sciences: Vol. 10 : Iss. 1 , Article 12. \n",
    " DOI: http://dx.doi.org/10.18576/amis/100112 \n",
    " Available at: https://dc.naturalspublishing.com/amis/vol10/iss1/12 \n",
    " \n",
    " [3] Kevin Verbeek and Subhash Suri. 2014. Metric Embedding, Hyperbolic Space, and Social Networks. In Proceedings of the thirtieth annual symposium on Computational geometry (SOCG'14). Association for Computing Machinery, New York, NY, USA, 501–510. DOI:https://doi.org/10.1145/2582112.2582139 \n",
    " \n",
    " [4] Jörg A Walter, H-MDS: a new approach for interactive visualization with multidimensional scaling in the hyperbolic space, Information Systems, Volume 29, Issue 4, 2004, Pages 273-292, ISSN 0306-4379, https://doi.org/10.1016/j.is.2003.10.002. \n",
    " \n",
    " [5] R. Kleinberg. 2007. Geographic Routing Using Hyperbolic Space. In Proceedings of the IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications. IEEE Computer Society, USA, 1902–1909. DOI:https://doi.org/10.1109/INFCOM.2007.221 \n",
    " \n",
    " [6] R. Krauthgamer and J. R. Lee, \"Algorithms on negatively curved spaces,\" 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06), 2006, pp. 119-132, doi: 10.1109/FOCS.2006.9. \n",
    " \n",
    " [7] Krioukov D, Papadopoulos F, Vahdat A, Boguñá M. Curvature and temperature of complex networks. Phys Rev E Stat Nonlin Soft Matter Phys. 2009 Sep;80(3 Pt 2):035101. doi: 10.1103/PhysRevE.80.035101. Epub 2009 Sep 23. PMID: 19905164. \n",
    " \n",
    " [8] A. Cvetkovski and M. Crovella, \"Hyperbolic Embedding and Routing for Dynamic Graphs,\" IEEE INFOCOM 2009, 2009, pp. 1647-1655, doi: 10.1109/INFCOM.2009.5062083. \n",
    " \n",
    " [9] Y. Shavitt and T. Tankel, \"Hyperbolic Embedding of Internet Graph for Distance Estimation and Overlay Construction,\" in IEEE/ACM Transactions on Networking, vol. 16, no. 1, pp. 25-36, Feb. 2008, doi: 10.1109/TNET.2007.899021. \n",
    " \n",
    " [10] Matthias Hamann. On the Tree-Likeness of Hyperbolic Spaces. Mathematical Proceedings of the Cambridge Philosophical Society, 164(2):345–361, 2018. doi: 10.1017/ S0305004117000238. \n",
    " \n",
    " [11] Anna Dyubina and Iosif Polterovich. Explicit Constructions of Universal R-Trees and Asymptotic Geometry of Hyperbolic Spaces. Bulletin of the London Mathematical Society, 33 (6):727?734, Nov 2001. \n",
    " \n",
    " [12] M.Bonk and O.Schramm. Embeddings of Gromov Hyperbolic Spaces. Geometric & Functional Analysis GAFA, 10(2):266–306, Jun 2000. \n",
    " \n",
    " [13] Ittai Abraham, Mahesh Balakrishnan, Fabian Kuhn, Dahlia Malkhi, Venugopalan Ramasubramanian, and Kunal Talwar. Reconstructing Approximate Tree Metrics. In Proceedings of the Twenty-sixth Annual ACM Symposium on Principles of Distributed Computing, PODC ’07, pages 43–52, New York, NY, USA, 2007. ACM. \n",
    " \n",
    " [14] M.R. Bridson and A. Häfliger. Metric Spaces of Non-Positive Curvature. Grundlehren der mathematischen Wissenschaften. Springer Berlin Heidelberg, 2013. ISBN 9783662124949. \n",
    " \n",
    " [15] Victor Chepoi, Feodor Dragan, Bertrand Estellon, Michel Habib, and Yann Vaxès. Diameters, Centers, and Approximating Trees of δ-Hyperbolic Geodesic Spaces and Graphs. In Proceedings of the Twenty-fourth Annual Symposium on Computational Geometry, SCG ’08, pages 59–68, New York, NY, USA, 2008. ACM. \n",
    " \n",
    " [16] Anna Klimovskaia, David Lopez-Paz, Léon Bottou, and Maximilian Nickel. Poincaré Maps for Analyzing complex Hierarchies in Single-Cell Data. bioRxiv, 2019. doi: 10.1101/689547. \n",
    " \n",
    " [17] Maximilian Nickel and Douwe Kiela. Poincaré Embeddings for Learning Hierarchical Representations. In NIPS, 2017. \n",
    " \n",
    " [18] Frederic Sala, Chris De Sa, Albert Gu, and Christopher Re. Representation Tradeoffs for Hy- perbolic Embeddings. Proceedings of the 35th International Conference on Machine Learning, pages 4460–4469, July 2018. \n",
    " \n",
    " [19] Rik Sarkar. Low Distortion Delaunay Embedding of Trees in Hyperbolic Plane. In Proceedings of the 19th International Conference on Graph Drawing, GD’11, pages 355–366, Berlin, Heidelberg, 2012. Springer-Verlag. \n",
    " \n",
    " [20] B. P. Chamberlin, J. Clough, and M. P. Deisenroth, \"Neural embeddings of graphs in hyperbolic space\", arXiv 2017\n",
    " \n",
    " [21] M. E. Newman, “Power laws, pareto distributions and zipf’s law,” Contemporary physics, 2005.\n",
    "\n",
    " [22] H. W. Lin and M. Tegmark, “Critical behavior in physics and probabilistic formal languages,” Entropy, 2017.\n",
    "\n",
    " [23] K. Katayama and E. W. Maina, “Indexing method for hierarchical graphs based on relation among interlacing sequences of eigenvalues,” Journal of information processing, 2015.\n",
    "\n",
    " [24] R. Shimizu, Y. Mukuta, and T. Harada, “Hyperbolic neural networks++,” 2021.\n",
    " \n",
    " [25] M. Boguna ́, F. Papadopoulos, and D. Krioukov, “Sustaining the internet with hyperbolic mapping,” Nature communications, 2010.\n",
    "\n",
    " [26] B. Tadic ́, M. Andjelkovic ́, and M. Sˇuvakov, “Origin of hyperbolicity in brain-to-brain coordination networks,” Frontiers in Physics, 2018.\n",
    " \n",
    " [27] G.Garcia-Pe ́rez,M.Bogun ̃a ́,A.Allard,andM.A ́.Serrano,“Thehidden hyperbolic geometry of international trade: World trade atlas 1870– 2013,” Scientific reports, 2016.\n",
    "\n",
    " [28] M. Keller-Ressel and S. Nargang, “The hyperbolic geometry of financial networks,” Scientific reports, 2021.\n",
    " \n",
    " [29] R. Krauthgamer and J. R. Lee, “Algorithms on negatively curved spaces,” in 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06). IEEE, 2006.\n",
    "\n",
    " [30] E. Begelfor and M. Werman, “The world is not always flat or learning curved manifolds,” School of Engineering and Computer Science, Hebrew University of Jerusalem., Tech. Rep, 2005.\n",
    "\n",
    " [31] M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst, “Geometric deep learning: going beyond euclidean data,” IEEE Signal Processing Magazine, 2017.\n",
    " \n",
    " [32] B. P. Chamberlain, S. R. Hardwick, D. R. Wardrope, F. Dzogang, F. Daolio, and S. Vargas, “Scalable hyperbolic recommender systems,” CoRR, 2019.\n",
    "\n",
    " [33] P. Kolyvakis, A. Kalousis, and D. Kiritsis, “Hyperkg: hyperbolic knowledge graph embeddings for knowledge base completion,” arXiv, 2019.\n",
    "\n",
    " [34] V. Khrulkov, L. Mirvakhabova, E. Ustinova, I. Oseledets, and V. Lempit- sky, “Hyperbolic image embeddings,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020.\n",
    " \n",
    " [35] Bhuwan Dhingra, Christopher J. Shallue, Mohammad Norouzi, Andrew M. Dai, and George E. Dahl. Embedding Text in Hyperbolic Spaces, 2018.\n",
    " \n",
    " [36] Louis J. Billera, Susan P. Holmes, and Karen Vogtmann. Geometry of the space of phylogenetic trees. Advances in Applied Mathematics, 27(4):733–767, 2001. ISSN 0196-8858. doi: https:// doi.org/10.1006/aama.2001.0759. URL https://www.sciencedirect.com/science/ article/pii/S0196885801907596.\n",
    " \n",
    " [37] Katherine St John. Review paper: The shape of phylogenetic treespace. Systematic Biology, 66:e83 – e94, 2017.\n",
    " \n",
    " [38] CubeRep: Learning Relations Between Different Views of Data. \n",
    " \n",
    " [39] O. Ganea, G. Be ́cigneul, and T. Hofmann, “Hyperbolic neural networks,” Advances in neural information processing systems, 2018.\n",
    "\n",
    " [40] C. Gulcehre, M. Denil, M. Malinowski, A. Razavi, R. Pascanu, K. M. Hermann, P. Battaglia, V. Bapst, D. Raposo, A. Santoro et al., “Hyperbolic attention networks,” arXiv, 2018.\n",
    "\n",
    " [41] M. Nickel and D. Kiela, “Learning continuous hierarchies in the lorentz model of hyperbolic geometry,” Proceedings of the 35-th International Conference on Machine Learning, PMLR, 2018.\n",
    "\n",
    " [42] Q. Liu, M. Nickel, and D. Kiela, “Hyperbolic graph neural networks,” in Advances in Neural Information Processing Systems, 2019.\n",
    "\n",
    " [43] I. Chami, Z. Ying, C. Re ́, and J. Leskovec, “Hyperbolic graph convolutional neural networks,” in Advances in neural information processing systems, 2019.\n",
    "\n",
    " [44] W. Peng, J. Shi, Z. Xia, and G. Zhao, “Mix dimension in poincare ́ geometry for 3d skeleton-based action recognition,” in Proceedings of the 28th ACM International Conference on Multimedia, 2020.\n",
    "\n",
    " [45] G. Bachmann, G. Be ́cigneul, and O. Ganea, “Constant curvature graph convolutional networks,” in International Conference on Machine Learning. PMLR, 2020.\n",
    "\n",
    " [46] D. J. Rezende, G. Papamakarios, S. Racaniere, M. S. Albergo, G. Kanwar, P. E. Shanahan, and K. Cranmer, “Normalizing flows on tori and spheres,” Proceedings of the 37th International Conference on Machine Learning, 2020.\n",
    " \n",
    " [47] Chen, W., Han, X., Lin, Y., Zhao, H., Liu, Z., Li, P., Sun, M., & Zhou, J. (2021). Fully Hyperbolic Neural Networks. ArXiv, abs/2105.14686.\n",
    " \n",
    " [48] Lensink, K., Haber, E., & Peters, B. (2019). Fully Hyperbolic Convolutional Neural Networks. ArXiv, abs/1905.10484.\n",
    " \n",
    " [50] Leimeister, M., & Wilson, B.J. (2018). Skip-gram word embeddings in hyperbolic space. ArXiv, abs/1809.01498.\n",
    " \n",
    " [51] Tifrea, A., Bécigneul, G., & Ganea, O. (2019). Poincaré GloVe: Hyperbolic Word Embeddings. ArXiv, abs/1810.06546."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOQ8KsdpR6fYXe6IlXS5dy0",
   "collapsed_sections": [],
   "name": "TreeEmbeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
